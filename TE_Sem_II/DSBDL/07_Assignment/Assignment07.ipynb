{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### **Assignment No 07**\n",
        "\n",
        "**Text Anatytics** <br/>\n",
        "1. Extract Sample document and apply following document preprocessing methods: Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization.<br/>\n",
        "2. Create representation of document by calculating Term Frequency and Inverse Document Frequency."
      ],
      "metadata": {
        "id": "Cs6L8D4tkJbJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MYewrrpcj06a"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import string\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_1i7MjXvmGgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download(\"wordnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xaIDoifmJW1",
        "outputId": "5d546eb4-bc23-4f1f-c15b-f69775f6c217"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.probability import FreqDist\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "nhvt89YumzhU"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qmBER7txkI4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Extract and clean the document**\n"
      ],
      "metadata": {
        "id": "3Ma14Ic3md7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/data.txt\",\"r\") as file:\n",
        "  text = file.read()\n",
        "\n",
        "\n",
        "# All ASCII Chars\n",
        "alphabet = string.printable\n",
        "\n",
        "# clean the text\n",
        "def clean_data(text):\n",
        "  return''.join([word for word in text.lower() if word in alphabet])\n",
        "\n",
        "clean_data(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "0eXZvmvUkVpZ",
        "outputId": "dbf65fca-e341-43c9-a245-3e06b45e475f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"python is a high-level, interpreted programming language created by guido van rossum and first released in 1991. it is designed with an emphasis on code readability, and its syntax allows programmers to express concepts in fewer lines of code than would be possible in languages such as c++ or java.\\n\\npython supports multiple programming paradigms, including procedural, object-oriented, and functional programming. in simpler terms, this means its flexible and allows you to write code in different ways, whether that's like giving the computer a to-do list (procedural), creating digital models of things or concepts (object-oriented), or treating your code like a math problem (functional).\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Tokenization**: <br/>\n",
        "Breaking a text into smaller units, typically words or phrases, to facilitate further analysis."
      ],
      "metadata": {
        "id": "an8hpMNblvf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkfyRzgfluyb",
        "outputId": "2273fad9-4de1-4e77-af6d-308af7b74255"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Python', 'is', 'a', 'high-level', ',', 'interpreted', 'programming', 'language', 'created', 'by', 'Guido', 'van', 'Rossum', 'and', 'first', 'released', 'in', '1991', '.', 'It', 'is', 'designed', 'with', 'an', 'emphasis', 'on', 'code', 'readability', ',', 'and', 'its', 'syntax', 'allows', 'programmers', 'to', 'express', 'concepts', 'in', 'fewer', 'lines', 'of', 'code', 'than', 'would', 'be', 'possible', 'in', 'languages', 'such', 'as', 'C++', 'or', 'Java', '.', 'Python', 'supports', 'multiple', 'programming', 'paradigms', ',', 'including', 'procedural', ',', 'object-oriented', ',', 'and', 'functional', 'programming', '.', 'In', 'simpler', 'terms', ',', 'this', 'means', 'it', '’', 's', 'flexible', 'and', 'allows', 'you', 'to', 'write', 'code', 'in', 'different', 'ways', ',', 'whether', 'that', \"'s\", 'like', 'giving', 'the', 'computer', 'a', 'to-do', 'list', '(', 'procedural', ')', ',', 'creating', 'digital', 'models', 'of', 'things', 'or', 'concepts', '(', 'object-oriented', ')', ',', 'or', 'treating', 'your', 'code', 'like', 'a', 'math', 'problem', '(', 'functional', ')', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. POS Parts of Speech Tagging**:<br/> Assigning grammatical categories (like noun, verb, adjective) to each word in a text based on its context and meaning."
      ],
      "metadata": {
        "id": "MHqaL0xgnkrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tags = nltk.pos_tag(tokens)\n",
        "print(pos_tags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnwDkwNZkqq8",
        "outputId": "9cdb17f8-1239-461b-e04a-79898bebf930"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Python', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('high-level', 'JJ'), (',', ','), ('interpreted', 'JJ'), ('programming', 'NN'), ('language', 'NN'), ('created', 'VBN'), ('by', 'IN'), ('Guido', 'NNP'), ('van', 'NN'), ('Rossum', 'NNP'), ('and', 'CC'), ('first', 'RB'), ('released', 'VBN'), ('in', 'IN'), ('1991', 'CD'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('designed', 'VBN'), ('with', 'IN'), ('an', 'DT'), ('emphasis', 'NN'), ('on', 'IN'), ('code', 'NN'), ('readability', 'NN'), (',', ','), ('and', 'CC'), ('its', 'PRP$'), ('syntax', 'NN'), ('allows', 'VBZ'), ('programmers', 'NNS'), ('to', 'TO'), ('express', 'VB'), ('concepts', 'NNS'), ('in', 'IN'), ('fewer', 'JJR'), ('lines', 'NNS'), ('of', 'IN'), ('code', 'NN'), ('than', 'IN'), ('would', 'MD'), ('be', 'VB'), ('possible', 'JJ'), ('in', 'IN'), ('languages', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('C++', 'NNP'), ('or', 'CC'), ('Java', 'NNP'), ('.', '.'), ('Python', 'NNP'), ('supports', 'VBZ'), ('multiple', 'JJ'), ('programming', 'NN'), ('paradigms', 'NN'), (',', ','), ('including', 'VBG'), ('procedural', 'JJ'), (',', ','), ('object-oriented', 'JJ'), (',', ','), ('and', 'CC'), ('functional', 'JJ'), ('programming', 'NN'), ('.', '.'), ('In', 'IN'), ('simpler', 'NN'), ('terms', 'NNS'), (',', ','), ('this', 'DT'), ('means', 'VBZ'), ('it', 'PRP'), ('’', 'NNP'), ('s', 'VBD'), ('flexible', 'JJ'), ('and', 'CC'), ('allows', 'VBZ'), ('you', 'PRP'), ('to', 'TO'), ('write', 'VB'), ('code', 'NN'), ('in', 'IN'), ('different', 'JJ'), ('ways', 'NNS'), (',', ','), ('whether', 'IN'), ('that', 'DT'), (\"'s\", 'VBZ'), ('like', 'IN'), ('giving', 'VBG'), ('the', 'DT'), ('computer', 'NN'), ('a', 'DT'), ('to-do', 'JJ'), ('list', 'NN'), ('(', '('), ('procedural', 'JJ'), (')', ')'), (',', ','), ('creating', 'VBG'), ('digital', 'JJ'), ('models', 'NNS'), ('of', 'IN'), ('things', 'NNS'), ('or', 'CC'), ('concepts', 'NNS'), ('(', '('), ('object-oriented', 'JJ'), (')', ')'), (',', ','), ('or', 'CC'), ('treating', 'VBG'), ('your', 'PRP$'), ('code', 'NN'), ('like', 'IN'), ('a', 'DT'), ('math', 'NN'), ('problem', 'NN'), ('(', '('), ('functional', 'JJ'), (')', ')'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Stop Words Removal**:<br/> Eliminating common words (like \"the\", \"is\", \"and\") from a text that may not carry significant meaning for analysis purposes."
      ],
      "metadata": {
        "id": "U-JYJT9jogcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tXvZYN2n0VR",
        "outputId": "85a4b475-395c-4579-ec1a-92142bc8c6f0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Python', 'high-level', ',', 'interpreted', 'programming', 'language', 'created', 'Guido', 'van', 'Rossum', 'first', 'released', '1991', '.', 'designed', 'emphasis', 'code', 'readability', ',', 'syntax', 'allows', 'programmers', 'express', 'concepts', 'fewer', 'lines', 'code', 'would', 'possible', 'languages', 'C++', 'Java', '.', 'Python', 'supports', 'multiple', 'programming', 'paradigms', ',', 'including', 'procedural', ',', 'object-oriented', ',', 'functional', 'programming', '.', 'simpler', 'terms', ',', 'means', '’', 'flexible', 'allows', 'write', 'code', 'different', 'ways', ',', 'whether', \"'s\", 'like', 'giving', 'computer', 'to-do', 'list', '(', 'procedural', ')', ',', 'creating', 'digital', 'models', 'things', 'concepts', '(', 'object-oriented', ')', ',', 'treating', 'code', 'like', 'math', 'problem', '(', 'functional', ')', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Stemming** <br/>\n",
        "Reducing words to their base or root form, typically by removing suffixes, to normalize variations of words."
      ],
      "metadata": {
        "id": "ZGp1pLAqpCTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "porter = PorterStemmer()\n",
        "\n",
        "stemmed_words = [porter.stem(word) for word in filtered_tokens]\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwWVKgpio5aJ",
        "outputId": "0a8d75cf-a8c6-4078-8ae9-c8d378faff2c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['python', 'high-level', ',', 'interpret', 'program', 'languag', 'creat', 'guido', 'van', 'rossum', 'first', 'releas', '1991', '.', 'design', 'emphasi', 'code', 'readabl', ',', 'syntax', 'allow', 'programm', 'express', 'concept', 'fewer', 'line', 'code', 'would', 'possibl', 'languag', 'c++', 'java', '.', 'python', 'support', 'multipl', 'program', 'paradigm', ',', 'includ', 'procedur', ',', 'object-ori', ',', 'function', 'program', '.', 'simpler', 'term', ',', 'mean', '’', 'flexibl', 'allow', 'write', 'code', 'differ', 'way', ',', 'whether', \"'s\", 'like', 'give', 'comput', 'to-do', 'list', '(', 'procedur', ')', ',', 'creat', 'digit', 'model', 'thing', 'concept', '(', 'object-ori', ')', ',', 'treat', 'code', 'like', 'math', 'problem', '(', 'function', ')', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Lemmetization**<br/>\n",
        "Similar to stemming but aims to return the base or dictionary form of a word (lemma), considering its morphological variations."
      ],
      "metadata": {
        "id": "PSl0-ZO2pzO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxyimbeipynv",
        "outputId": "43d64fd6-c78d-47f7-e59b-0a00dcd63065"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Python', 'high-level', ',', 'interpreted', 'programming', 'language', 'created', 'Guido', 'van', 'Rossum', 'first', 'released', '1991', '.', 'designed', 'emphasis', 'code', 'readability', ',', 'syntax', 'allows', 'programmer', 'express', 'concept', 'fewer', 'line', 'code', 'would', 'possible', 'language', 'C++', 'Java', '.', 'Python', 'support', 'multiple', 'programming', 'paradigm', ',', 'including', 'procedural', ',', 'object-oriented', ',', 'functional', 'programming', '.', 'simpler', 'term', ',', 'mean', '’', 'flexible', 'allows', 'write', 'code', 'different', 'way', ',', 'whether', \"'s\", 'like', 'giving', 'computer', 'to-do', 'list', '(', 'procedural', ')', ',', 'creating', 'digital', 'model', 'thing', 'concept', '(', 'object-oriented', ')', ',', 'treating', 'code', 'like', 'math', 'problem', '(', 'functional', ')', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2 : Representation of Document**\n",
        "\n",
        "**Term Frequency (TF):** Measuring how frequently a term occurs in a document relative to the total number of terms in that document.<br/>\n",
        "\n",
        "**Inverse Document Frequency (IDF):** Measuring the rarity or commonness of a term across all documents in a corpus.\n",
        "\n",
        "\n",
        "**TF-IDF (Term Frequency-Inverse Document Frequency)**: Combining TF and IDF to evaluate the importance of a term in a document relative to a corpus."
      ],
      "metadata": {
        "id": "0_3Wcm62qbxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf = FreqDist(stemmed_words)\n",
        "corpus = [text]\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_vectorizer.fit(corpus)\n",
        "idf = tfidf_vectorizer.idf_\n",
        "\n",
        "\n",
        "tfidf = {word: tf[word] * idf[i] for i, word in enumerate(tf.keys())}\n",
        "print(\"Term Frequency:\", tf)\n",
        "print(\"TF-IDF:\", tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvmYK9wqph0p",
        "outputId": "7d1b6524-4d4f-4d17-e461-7928fc740e25"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Term Frequency: <FreqDist with 59 samples and 88 outcomes>\n",
            "TF-IDF: {'python': 2.0, 'high-level': 1.0, ',': 9.0, 'interpret': 1.0, 'program': 3.0, 'languag': 2.0, 'creat': 2.0, 'guido': 1.0, 'van': 1.0, 'rossum': 1.0, 'first': 1.0, 'releas': 1.0, '1991': 1.0, '.': 4.0, 'design': 1.0, 'emphasi': 1.0, 'code': 4.0, 'readabl': 1.0, 'syntax': 1.0, 'allow': 2.0, 'programm': 1.0, 'express': 1.0, 'concept': 2.0, 'fewer': 1.0, 'line': 1.0, 'would': 1.0, 'possibl': 1.0, 'c++': 1.0, 'java': 1.0, 'support': 1.0, 'multipl': 1.0, 'paradigm': 1.0, 'includ': 1.0, 'procedur': 2.0, 'object-ori': 2.0, 'function': 2.0, 'simpler': 1.0, 'term': 1.0, 'mean': 1.0, '’': 1.0, 'flexibl': 1.0, 'write': 1.0, 'differ': 1.0, 'way': 1.0, 'whether': 1.0, \"'s\": 1.0, 'like': 2.0, 'give': 1.0, 'comput': 1.0, 'to-do': 1.0, 'list': 1.0, '(': 3.0, ')': 3.0, 'digit': 1.0, 'model': 1.0, 'thing': 1.0, 'treat': 1.0, 'math': 1.0, 'problem': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MrywcJ7WrZZv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}